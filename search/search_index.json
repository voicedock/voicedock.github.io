{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"VoiceDock \u2014 a platform for creating voice assistants","text":"<p>Many scientists and researchers create interesting models, but they are difficult to apply in real projects. Firstly, all models have a different API, and secondly, there may not be an API or the project may be difficult to launch.</p> <p>VoiceDock solves these problems by providing a universal API specification and ready-to-use applications.</p>"},{"location":"#an-example-of-using-voicedock","title":"An example of using VoiceDock","text":""},{"location":"#ready-to-use-apps","title":"Ready-to-use apps","text":"<p>Check out ready-to-use VoiceDock API applications that can be run on a server using docker.</p> <ul> <li>Explore apps</li> </ul>"},{"location":"#universal-api-specification","title":"Universal API Specification","text":"<p>Check out the API specification to implement it and create a new application.</p> <ul> <li>Explore specs</li> </ul>"},{"location":"#what-is-this-project-for","title":"What is this project for?","text":"<p>Now, AI technologies are available only to large corporations and researchers. Ordinary developers have access to either cloud-based APIs or difficult-to-scalable solutions.</p> <p>VoiceDock mission:</p> <ul> <li>Unify API access to AI models</li> <li>Provide ready-made implementations that can be easily run on a server in docker</li> <li>Create a voice assistant based on this base, launched locally and comparable in quality to the products of large corporations</li> </ul>"},{"location":"apps/","title":"VoiceDock Apps","text":"<p>VoiceDock Apps are ready-to-use applications that implement the VoiceDock API.</p>"},{"location":"apps/#official","title":"Official","text":"<ul> <li>STT Whisper - Automatic text recognition for many languages based on the \"whisper\" neural network.</li> <li>TTS Piper - High-quality voice synthesis with support for many languages.</li> <li>AI chat llama - Text generation based on any AI models in ggml format.</li> </ul>"},{"location":"apps/#community","title":"Community","text":"<p>It's empty here</p> <p>Please let me know if you have made your own implementation of the VoiceDock API.</p>"},{"location":"apps/aichatllama/","title":"AI chat llama","text":"<p>Llama.cpp based VoiceDock AI chat implementation. Provides gRPC API for AI chat based on llama.cpp project. Provides download of new model via API.</p>"},{"location":"apps/aichatllama/#features","title":"Features","text":"<ul> <li>Browse and download AI model (models in ggml format)</li> <li>Query-based text generation through AI model</li> <li>GPU support</li> <li>Fast performance on cpu</li> </ul>"},{"location":"apps/aichatllama/#installation","title":"Installation","text":"<p>Create directories for model data and configuration: <pre><code>mkdir dataset\nmkdir config\n</code></pre> Create a <code>config/aichatllama.json</code> configuration file or download an example configuration: <pre><code>curl -o config/aichatllama.json https://raw.githubusercontent.com/voicedock/aichatllama/main/config/aichatllama.json\n</code></pre></p> Docker (on CPU)Docker (on GPU) <pre><code>docker run --rm \\\n-v \"$(pwd)/config:/data/config\" \\\n-v \"$(pwd)/dataset:/data/dataset\" \\\n-p 9999:9999 \\\nghcr.io/voicedock/aichatllama:latest aichatllama\n</code></pre> <pre><code>docker run --rm --gpus all \\\n-v \"$(pwd)/config:/data/config\" \\\n-v \"$(pwd)/dataset:/data/dataset\" \\\n-e LLAMA_GPU_LAYERS=2 \\\n-p 9999:9999 \\\nghcr.io/voicedock/aichatllama:gpu aichatllama\n</code></pre>"},{"location":"apps/aichatllama/#configuration","title":"Configuration","text":"<p>See on Github.</p>"},{"location":"apps/sttwhisper/","title":"STT Whisper","text":"<p>Whisper.cpp based VoiceDock STT implementation. Provides gRPC API for high quality speech-to-text (from raw PCM stream) based on Whisper.cpp project. Provides download of new language packs via API.</p>"},{"location":"apps/sttwhisper/#features","title":"Features","text":"<ul> <li>Browse and download language packs (models in ggml format)</li> <li>Speech to text conversion for 99+ languages</li> <li>Automatic language recognition</li> <li>GPU support</li> </ul>"},{"location":"apps/sttwhisper/#installation","title":"Installation","text":"<p>Create directories for model data and configuration: <pre><code>mkdir dataset\nmkdir config\n</code></pre> Create a <code>config/sttwhisper.json</code> configuration file or download an example configuration: <pre><code>curl -o config/sttwhisper.json https://raw.githubusercontent.com/voicedock/sttwhisper/main/config/sttwhisper.json\n</code></pre></p> Docker (on CPU)Docker (on GPU) <pre><code>docker run --rm \\\n-v \"$(pwd)/config:/data/config\" \\\n-v \"$(pwd)/dataset:/data/dataset\" \\\n-p 9999:9999 \\\nghcr.io/voicedock/sttwhisper:latest sttwhisper\n</code></pre> <pre><code>docker run --rm --gpus all \\\n-v \"$(pwd)/config:/data/config\" \\\n-v \"$(pwd)/dataset:/data/dataset\" \\\n-p 9999:9999 \\\nghcr.io/voicedock/sttwhisper:gpu sttwhisper\n</code></pre>"},{"location":"apps/sttwhisper/#configuration","title":"Configuration","text":"<p>See on Github.</p>"},{"location":"apps/sttwhisper/#languages-support","title":"Languages support","text":"<p>en, zh, de, es, ru, ko, fr, ja, pt, tr, pl, ca, nl, ar, sv, it, id, hi, fi, vi, iw, uk, el, ms, cs, ro, da, hu, ta, no, th, ur, hr, bg, lt, la, mi, ml, cy, sk, te, fa, lv, bn, sr, az, sl, kn, et, mk, br, eu, is, hy, ne, mn, bs, kk, sq, sw, gl, mr, pa, si, km, sn, yo, so, af, oc, ka, be, tg, sd, gu, am, yi, lo, uz, fo, ht, ps, tk, nn, mt, sa, lb, my, bo, tl, mg, as, tt, haw, ln, ha, ba, jw.</p>"},{"location":"apps/ttspiper/","title":"TTS Piper","text":"<p>Piper based VoiceDock TTS implementation. Provides gRPC API for high quality text-to-speech (raw PCM stream) based on Piper project. Provides download of new languages and voices via API.</p>"},{"location":"apps/ttspiper/#features","title":"Features","text":"<ul> <li>Browse and download language and voice</li> <li>Text to speech conversion for 27+ languages (see samples)</li> <li>Fast performance on cpu</li> </ul>"},{"location":"apps/ttspiper/#installation","title":"Installation","text":"<p>Create directories for model data and configuration: <pre><code>mkdir dataset\nmkdir config\n</code></pre> Create a <code>config/ttspiper.json</code> configuration file or download an example configuration: <pre><code>curl -o config/ttspiper.json https://raw.githubusercontent.com/voicedock/ttspiper/main/config/ttspiper.json\n</code></pre> Start in Docker: <pre><code>docker run --rm \\\n-v \"$(pwd)/config:/data/config\" \\\n-v \"$(pwd)/dataset:/data/dataset\" \\\n-p 9999:9999 \\\nghcr.io/voicedock/ttspiper:latest ttspiper\n</code></pre></p>"},{"location":"apps/ttspiper/#configuration","title":"Configuration","text":"<p>See on Github.</p>"},{"location":"apps/ttspiper/#languages-support","title":"Languages support","text":"<ul> <li>Catal\u00e0 (Catalan, Spain)</li> <li>Dansk (Danish, Denmark)</li> <li>Deutsch (German, Germany)</li> <li>\u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac (Greek, Greece)</li> <li>English (English, Great Britain)</li> <li>English (English, United States)</li> <li>Espa\u00f1ol (Spanish, Spain)</li> <li>Espa\u00f1ol (Spanish, Mexico)</li> <li>Suomi (Finnish, Finland)</li> <li>Fran\u00e7ais (French, France)</li> <li>\u00edslenska (Icelandic, Iceland)</li> <li>Italiano (Italian, Italy)</li> <li>\u10e5\u10d0\u10e0\u10d7\u10e3\u10da\u10d8 \u10d4\u10dc\u10d0 (Georgian, Georgia)</li> <li>\u049b\u0430\u0437\u0430\u049b\u0448\u0430 (Kazakh, Kazakhstan)</li> <li>\u0928\u0947\u092a\u093e\u0932\u0940 (Nepali, Nepal)</li> <li>Nederlands (Dutch, Belgium)</li> <li>Nederlands (Dutch, Netherlands)</li> <li>Norsk (Norwegian, Norway)</li> <li>Polski (Polish, Poland)</li> <li>Portugu\u00eas (Portuguese, Brazil)</li> <li>\u0420\u0443\u0441\u0441\u043a\u0438\u0439 (Russian, Russia)</li> <li>Svenska (Swedish, Sweden)</li> <li>Kiswahili (Swahili, Democratic Republic of the Congo)</li> <li>\u0443\u043a\u0440\u0430\u0457\u0301\u043d\u0441\u044c\u043a\u0430 \u043c\u043e\u0301\u0432\u0430 (Ukrainian, Ukraine)</li> <li>Ti\u1ebfng Vi\u1ec7t (Vietnamese, Vietnam)</li> <li>\u7b80\u4f53\u4e2d\u6587 (Chinese, China)</li> </ul>"},{"location":"specs/","title":"API proto specification","text":"<p>VoiceDock provides a modular approach. For each module type, the gRPC API interaction specification is described in the Protocol Buffers format.</p> <p>The VoiceDock concept is aimed at creating a universal and simple industrial-grade API that solves problems in the field of creating digital assistants, human interaction with artificial intelligence and related areas.</p> <p>The mission of VoiceDock is to quickly adapt new research by scientists for use in production. So that previously written code can quickly switch to using the new implementation. It is enough just to create an implementation of the gRPC API module for the new algorithm.</p>"},{"location":"specs/#api-overview","title":"API Overview","text":"<ul> <li>STT API - speech to text. (ASR - Automatic Speech Recognition).</li> <li>TTS API - text to speech.</li> <li>AI Chat API - text interaction with artificial intelligence</li> </ul>"},{"location":"specs/#stt-api","title":"STT API","text":"<p>The API receives an audio stream in PCM format (int 16 bit little-endian bytes) and returns a stream of recognized text tokens.</p> proto stt_api.proto proto version v1 implementation example sttwhisper area of application <ul><li>voice assistant</li><li>recognition of voice messages in instant messengers</li><li>Next gen interactive voice response (IVR)</li><li>Next gen voice answering machine</li><li>smart voice recorder</li><li>and others</li></ul>"},{"location":"specs/#tts-api","title":"TTS API","text":"<p>The API gets the text, language, speaker name and synthesizes the voice audio stream in PCM format (little-endian 16-bit bytes).</p> proto tts_api.proto proto version v1 implementation example ttspiper area of application <ul><li>voice assistant</li><li>Next gen interactive voice response (IVR)</li><li>Next gen voice answering machine</li><li>and others</li></ul>"},{"location":"specs/#ai-chat-api","title":"AI Chat API","text":"<p>The API accepts text and returns a stream of generated text tokens.</p> proto aichat_api.proto proto version v1 implementation example aichatllama area of application <ul><li>voice assistant</li><li>Next gen interactive voice response (IVR)</li><li>Next gen voice answering machine</li><li>Text summary service</li><li>and others</li></ul>"}]}